{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abab51b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt, freqz, hilbert\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.interpolate import CubicSpline, interp1d\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff58aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_gps_time(header_values):\n",
    "    \"\"\"Converts GPS time in milliseconds to week number, seconds-of-week, and UTC date\"\"\"\n",
    "    gps_seconds_total = header_values // 1000\n",
    "    gps_milliseconds = header_values % 1000\n",
    "    #gps_seconds_total -= 18\n",
    "    gps_weeks = gps_seconds_total // (7 * 24 * 3600)\n",
    "    gps_seconds = (gps_seconds_total % (7 * 24 * 3600)) + (gps_milliseconds / 1000.0)\n",
    "    gps_epoch = datetime(1980, 1, 6)\n",
    "    utc_dates = np.array([gps_epoch + timedelta(weeks=int(week), seconds=float(sec)) \n",
    "                          for week, sec in zip(gps_weeks, gps_seconds)])\n",
    "    hms_time = [utc.strftime(\"%H:%M:%S.%f\")[:-3] for utc in utc_dates]\n",
    "    return gps_weeks, gps_seconds, utc_dates, hms_time\n",
    "\n",
    "def load_motion_data(file_path, data_start=18):\n",
    "    \"\"\" Load GPS/IMU motion data from NovAtel logs\"\"\"\n",
    "    dtypes = [\n",
    "        ('time', 'U10'),  \n",
    "        ('date', 'U10'),\n",
    "        ('week_number', 'U10'),\n",
    "        ('seconds_of_week', 'f8'),\n",
    "        ('lat', 'f8'),\n",
    "        ('lon', 'f8'),\n",
    "        ('height-ell', 'f8'),\n",
    "        ('height-msl', 'f8'),\n",
    "        ('undulation', 'f8'),\n",
    "        ('x_ecef', 'f8'),\n",
    "        ('y_ecef', 'f8'),\n",
    "        ('z_ecef', 'f8'),\n",
    "        ('pitch', 'f8'),\n",
    "        ('roll', 'f8'),\n",
    "        ('heading', 'f8'),\n",
    "        ('cog', 'f8')\n",
    "    ]\n",
    "    \n",
    "    data = np.genfromtxt(file_path, skip_header=data_start, dtype=dtypes)\n",
    "    return data\n",
    "\n",
    "def extract_motion_data(data, gps_start_seconds, gps_end_seconds):\n",
    "    \"\"\"Extracts motion data for the given SAR data time range.\"\"\"\n",
    "    gps_seconds = data['seconds_of_week']\n",
    "    sorted_indices = np.argsort(gps_seconds)\n",
    "    gps_seconds = gps_seconds[sorted_indices]\n",
    "    data = data[sorted_indices]\n",
    "    start_idx = np.searchsorted(gps_seconds, gps_start_seconds, side='left')\n",
    "    end_idx = np.searchsorted(gps_seconds, gps_end_seconds, side='right')\n",
    "    start_idx = max(0, start_idx - 1)\n",
    "    end_idx = min(len(gps_seconds) - 1, end_idx)\n",
    "    extracted_motion = data[start_idx:end_idx + 1]\n",
    "    return extracted_motion\n",
    "\n",
    "def resample_motion_data(motion_data, radar_time_grid):\n",
    "    \"\"\"Resamples motion data using a CubicSpline to match the SAR time grid.\"\"\"\n",
    "    motion_timestamps = motion_data['seconds_of_week']\n",
    "    resampled_motion = np.zeros(len(radar_time_grid), dtype=motion_data.dtype)\n",
    "    resampled_motion['seconds_of_week'] = np.round(radar_time_grid, decimals=6)\n",
    "    for field in motion_data.dtype.names:\n",
    "        if field in ['time', 'date', 'week_number']:\n",
    "            resampled_motion[field] = motion_data[field][0]\n",
    "            continue\n",
    "        motion_values = motion_data[field]\n",
    "        if np.issubdtype(motion_values.dtype, np.number):\n",
    "            interpolator = CubicSpline(motion_timestamps, motion_values, extrapolate=True)\n",
    "            resampled_motion[field] = np.round(interpolator(radar_time_grid), decimals=6)\n",
    "        else:\n",
    "            resampled_motion[field] = motion_data[field][0]\n",
    "    return resampled_motion\n",
    "\n",
    "def sinc_interp_1d(data, x_actual, x_uniform, sinc_window=8, window_type=None, beta=8.6):\n",
    "    \"\"\"Interpolate SAR data in azimuth using sinc-interpolation.\"\"\"\n",
    "\n",
    "    N_uniform = len(x_uniform)\n",
    "    N_rg = data.shape[1]\n",
    "    data_interp = np.zeros((N_uniform, N_rg), dtype=data.dtype)\n",
    "\n",
    "    dx = np.median(np.diff(x_actual))  #estimated spacing\n",
    "\n",
    "    for i, xu in enumerate(x_uniform):\n",
    "        #relative positions\n",
    "        rel_pos = (xu - x_actual) / dx\n",
    "\n",
    "        #limit to window\n",
    "        mask = np.abs(rel_pos) < sinc_window\n",
    "        rel = rel_pos[mask]\n",
    "\n",
    "        if len(rel) == 0:\n",
    "            continue\n",
    "\n",
    "        #sinc weights\n",
    "        weights = np.sinc(rel)\n",
    "\n",
    "        #window functions\n",
    "        if window_type == 'hamming':\n",
    "            window = np.hamming(len(rel))\n",
    "            weights *= window\n",
    "        elif window_type == 'hanning':\n",
    "            window = np.hanning(len(rel))\n",
    "            weights *= window\n",
    "        elif window_type == 'kaiser':\n",
    "            window = np.kaiser(len(rel), beta)\n",
    "            weights *= window\n",
    "\n",
    "        #normalize and interpolate\n",
    "        weights /= np.sum(weights)\n",
    "        data_interp[i] = np.dot(weights, data[mask])\n",
    "\n",
    "    return data_interp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5dd961",
   "metadata": {},
   "source": [
    "# Load Raw Radar Data: #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b831d0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def natural_sort_key(s):\n",
    "    \"\"\"Sort files naturally by extracting numeric parts.\"\"\"\n",
    "    return [int(text) if text.isdigit() else text for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "def load_data(directory, n_samp, header_samp, start_sample=0, end_sample=None, start_idx=0, stop_idx=-1):\n",
    "    \"\"\"Loads SAR data from binary files, allowing flexible sample range selection.\n",
    "    Inputs:\n",
    "    \n",
    "    n_samp: number of total samples (should be 100,004 for 2025 SNOWWI datasets)\n",
    "    header_samp: number of header samples (should be 4 for 2025 SNOWWI datasets)\n",
    "    start_sample: desired starting range sample\n",
    "    end_sample: desired ending range sample\n",
    "    start_idx: starting radar data file\n",
    "    stop_idx: ending radar data file\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    files = sorted(os.listdir(directory), key=natural_sort_key)\n",
    "    num_files = len(files)\n",
    "    \n",
    "    if stop_idx == -1 or stop_idx >= num_files:\n",
    "        stop_idx = num_files - 1\n",
    "    if start_idx < 0 or start_idx >= num_files or stop_idx < start_idx:\n",
    "        raise ValueError(\"Invalid start_idx or stop_idx range.\")\n",
    "    \n",
    "    selected_files = files[start_idx:stop_idx + 1]\n",
    "    num_selected_files = len(selected_files)\n",
    "    \n",
    "    first_file_path = os.path.join(directory, selected_files[0])\n",
    "    first_file_size = os.path.getsize(first_file_path)\n",
    "\n",
    "    #calculate records per file based on full `n_samp`\n",
    "    num_records_per_file = first_file_size // (n_samp * 2)\n",
    "    total_records = num_selected_files * num_records_per_file\n",
    "\n",
    "    #set default `end_sample` if not provided\n",
    "    if end_sample is None or end_sample > (n_samp - header_samp):\n",
    "        end_sample = n_samp - header_samp\n",
    "\n",
    "    if start_sample < 0 or start_sample >= end_sample:\n",
    "        raise ValueError(\"Invalid start_sample or end_sample range.\")\n",
    "\n",
    "    #compute the final number of samples to be loaded per record\n",
    "    num_samples_per_record = end_sample - start_sample\n",
    "\n",
    "    #pre-allocate arrays\n",
    "    header_array = np.empty((total_records, header_samp), dtype=np.uint16)\n",
    "    radar_data = np.empty((total_records, num_samples_per_record), dtype=np.int16)\n",
    "\n",
    "    record_idx = 0\n",
    "\n",
    "    for file in selected_files:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        \n",
    "        with open(file_path, 'rb') as f:\n",
    "            #read full records per file\n",
    "            data = np.fromfile(f, dtype=np.int16).reshape(-1, n_samp)\n",
    "            \n",
    "            num_records = data.shape[0]\n",
    "            header_array[record_idx:record_idx + num_records] = data[:, :header_samp]\n",
    "            radar_data[record_idx:record_idx + num_records] = data[:, header_samp + start_sample : header_samp + end_sample]\n",
    "\n",
    "            record_idx += num_records\n",
    "    \n",
    "    #convert header to integer values if necessary\n",
    "    bit_shifts = np.array([2**48, 2**32, 2**16, 2**0])\n",
    "    header_values = np.dot(header_array, bit_shifts)\n",
    "\n",
    "    return radar_data, header_values, start_sample, end_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708c2091",
   "metadata": {},
   "source": [
    "# Preprocessing: #\n",
    "The chirp scaling algorithm, like other frequency-domain SAR processing techniques, assumes an ideal flight geometry. A key requirement is uniform along-track spacing between azimuth samples. Because these algorithms rely on FFT operations, such uniformity must be enforced through resampling. Although non-uniform Fourier transform methods exist, they are not employed here.\n",
    "\n",
    "## Objectives: ##\n",
    "\n",
    "- Load radar data\n",
    "\n",
    "- Load motion (GPS/IMU) data\n",
    "\n",
    "- Estimate the constant platform velocity\n",
    "\n",
    "- Resample the radar data to achieve uniform azimuth spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a26974",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now() #let's time the computation\n",
    "\n",
    "\n",
    "sar_data_path = r'<path to the date files>'\n",
    "start_idx = 720 #these files contain corner reflectors\n",
    "stop_idx = 740\n",
    "\n",
    "radar_data, header_values, start_sample, end_sample = load_data(sar_data_path, n_samp=100004, header_samp=4, start_sample=0, end_sample=None, start_idx=start_idx, stop_idx=stop_idx)\n",
    "print('Radar Date Type: ', radar_data.dtype)\n",
    "print('Radar Data Shape: ', radar_data.shape) #should be of shape (Naz, Nrg)\n",
    "gps_weeks, gps_seconds, utc_dates, hms_time = convert_gps_time(header_values)\n",
    "\n",
    "motion_data_path = r'~/motion data/20250205_gm.txt'\n",
    "motion_data = load_motion_data(motion_data_path)\n",
    "\n",
    "extracted_motion = extract_motion_data(motion_data, gps_start_seconds=gps_seconds[0], gps_end_seconds=gps_seconds[-1])\n",
    "radar_time_grid = np.round(np.arange(gps_seconds[0], gps_seconds[-1], 1/1000), decimals=6) #prf means 1/1000 time spacing\n",
    "print(\"flightline segment start time:\", gps_seconds[0], \"flightline segment end time:\", gps_seconds[-1])\n",
    "resampled_motion = resample_motion_data(extracted_motion, radar_time_grid)\n",
    "\n",
    "#compute x,y,z velocities\n",
    "prf = 1e3\n",
    "dt = 1/prf\n",
    "\n",
    "vx = np.diff(resampled_motion['x_ecef']) / dt\n",
    "vx = np.append(vx, vx[-1])  #extend last value to match length\n",
    "vy = np.diff(resampled_motion['y_ecef']) / dt\n",
    "vy = np.append(vy, vy[-1])\n",
    "vz = np.diff(resampled_motion['z_ecef']) / dt\n",
    "vz = np.append(vz, vz[-1])\n",
    "\n",
    "velocity = np.sqrt(vx**2 + vy**2 + vz**2)  #instantaneous speed (m/s)\n",
    "\n",
    "distance = np.cumsum(velocity * dt)\n",
    "distance -= distance[0] #start at 0\n",
    "\n",
    "#create uniformly spaced distance vector\n",
    "uniform_distance = np.linspace(distance[0], distance[-1], len(distance))  # same number of samples\n",
    "\n",
    "#interpolate SAR data onto uniform distance grid (azimuth axis)\n",
    "resampled_data = np.zeros_like(radar_data, dtype=np.int16)\n",
    "for i in range(radar_data.shape[1]):  #loop over range bins\n",
    "    f = interp1d(distance, radar_data[:, i], kind='linear', fill_value=\"extrapolate\")\n",
    "    resampled_data[:, i] = f(uniform_distance)\n",
    "\n",
    "#compute average constant velocity\n",
    "total_distance = distance[-1] - distance[0]\n",
    "total_time = len(velocity) * dt\n",
    "constant_velocity = total_distance / total_time\n",
    "print(\"Constant velocity used:\", constant_velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b48ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_flight_direction(x_ecef, y_ecef, z_ecef):\n",
    "    \"\"\"Returns the (unit) direction vector of the reference trajectory.\"\"\"\n",
    "    coords = np.stack([x_ecef, y_ecef, z_ecef], axis=1)\n",
    "    mean = coords.mean(axis=0)\n",
    "    u, s, vh = np.linalg.svd(coords - mean)\n",
    "    direction = vh[0]\n",
    "    direction /= np.linalg.norm(direction)\n",
    "    return direction  #this is the local along-track direction\n",
    "\n",
    "def ecef_to_local(x_ecef, y_ecef, z_ecef, direction_vec, \n",
    "                  origin_ecef=None):\n",
    "    \"\"\"Converts arrays of ECEF coordinates into platform-centric (along, cross, up),\n",
    "    but first subtracts an origin so that 0,0,0 is your starting point.\"\"\"\n",
    "    #stack into an (N,3) array\n",
    "    coords = np.stack([x_ecef, y_ecef, z_ecef], axis=1)\n",
    "    #choose an origin: first sample or mean\n",
    "    if origin_ecef is None:\n",
    "        origin_ecef = coords[0] #or coords.mean(axis=0)\n",
    "    #shift so origin is zero\n",
    "    coords_rel = coords - origin_ecef\n",
    "    \n",
    "    #build constant unit-axes\n",
    "    z_unit = origin_ecef / np.linalg.norm(origin_ecef)  #up\n",
    "    x_unit = direction_vec                          \n",
    "    y_unit = np.cross(z_unit, x_unit);  y_unit /= np.linalg.norm(y_unit)\n",
    "    #re-orthogonalize X just to be safe\n",
    "    x_unit = np.cross(y_unit, z_unit);  x_unit /= np.linalg.norm(x_unit)\n",
    "    \n",
    "    #now project all points relative to origin\n",
    "    x_along = coords_rel @ x_unit\n",
    "    y_cross = coords_rel @ y_unit\n",
    "    z_up    = coords_rel @ z_unit\n",
    "\n",
    "    return x_along, y_cross, z_up\n",
    "\n",
    "def compute_ideal_trajectory(along_track, cross_track, up):\n",
    "    \"\"\"Fit a 3D straight line to (along_track, cross_track, up) platform-centric positions.\n",
    "    Returns arrays for along_ideal, cross_ideal, up_ideal (projected points on the ideal line),\n",
    "    oriented so “forward” is positive and anchored to start at (0,0,0).\"\"\"\n",
    "    #build Nx3 array & center on the mean\n",
    "    coords = np.stack([along_track, cross_track, up], axis=1)\n",
    "    mean   = coords.mean(axis=0)\n",
    "    M      = coords - mean\n",
    "\n",
    "    #PCA via SVD to get the principal direction\n",
    "    _, _, vh = np.linalg.svd(M, full_matrices=False)\n",
    "    direction = vh[0]           #unit-length up to sign\n",
    "\n",
    "    #make sure it points from start to end (not backwards)\n",
    "    if np.dot(direction, coords[-1] - coords[0]) < 0:\n",
    "        direction = -direction\n",
    "\n",
    "    #project every point onto that line\n",
    "    t_proj   = M @ direction               #scalar distance along the line for each sample\n",
    "    projected = mean + np.outer(t_proj, direction)\n",
    "\n",
    "    #shift so that the very first point is at the origin (0,0,0)\n",
    "    projected -= projected[0]\n",
    "\n",
    "    #unpack\n",
    "    along_ideal, cross_ideal, up_ideal = projected[:,0], projected[:,1], projected[:,2]\n",
    "    return along_ideal, cross_ideal, up_ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4a94a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#motion compensation terms\n",
    "times = resampled_motion['seconds_of_week'] - resampled_motion['seconds_of_week'][0]\n",
    "x = resampled_motion['x_ecef']\n",
    "y = resampled_motion['y_ecef']\n",
    "z = resampled_motion['z_ecef']\n",
    "elev = resampled_motion['heightell']\n",
    "roll = resampled_motion['roll']\n",
    "pitch = resampled_motion['pitch']\n",
    "cog = resampled_motion['cog']\n",
    "heading = resampled_motion['heading']\n",
    "\n",
    "cog_corrected = np.array(\n",
    "    [cog_i if cog_i < 180 else cog_i - 360 for cog_i in cog] #need to bound COG properly\n",
    ")\n",
    "yaw = np.mod(heading - cog_corrected + 360, 360) #yaw needs to be calculated from COG and Heading because it is not output by the NovAtel\n",
    "yaw_corrected = np.array(\n",
    "    [yaw_i if yaw_i < 180 else yaw_i - 360 for yaw_i in yaw]\n",
    ")\n",
    "\n",
    "#compute flight direction in ECEF\n",
    "direction_vec = compute_flight_direction(\n",
    "    resampled_motion['x_ecef'],\n",
    "    resampled_motion['y_ecef'],\n",
    "    resampled_motion['z_ecef'],\n",
    ")\n",
    "\n",
    "#convert ECEF to local (along-track, cross-track, up), zeroed at origin\n",
    "x_along, y_cross, z_up = ecef_to_local(\n",
    "    resampled_motion['x_ecef'],\n",
    "    resampled_motion['y_ecef'],\n",
    "    resampled_motion['z_ecef'],\n",
    "    direction_vec\n",
    ")\n",
    "\n",
    "#fit the ideal straight‐line trajectory in local frame\n",
    "x_along_ideal, y_cross_ideal, z_up_ideal = compute_ideal_trajectory(\n",
    "    x_along,\n",
    "    y_cross,\n",
    "    z_up\n",
    ")\n",
    "\n",
    "#deviations in cross-track and up dimensions for 1st-Order Motion Compensation (MOCO)\n",
    "delta_y = y_cross - y_cross_ideal\n",
    "print(\"Mean Cross Track Deviation: \", np.mean(delta_y))\n",
    "delta_z = z_up - z_up_ideal\n",
    "print(\"Mean Height Deviation: \", np.mean(delta_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe352e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_data = resampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#free up memory\n",
    "del sar_data_path, motion_data_path, gps_weeks, gps_seconds, utc_dates, hms_time, y_cross, z_up, x_along, y_cross_ideal \n",
    "del z_up_ideal, direction_vec, x_along_ideal, resampled_data, vx, vy, vz, cog, extracted_motion, resampled_motion\n",
    "del distance, header_values, heading, motion_data, radar_time_grid, yaw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3579e059",
   "metadata": {},
   "source": [
    "# Plot Un-Modified Motion: #\n",
    "This is useful for knowing how the motion is behaving over the flightline. It serves as a quick eye-ball check for how much squint is happening (mostly due to yaw)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00de93af",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 1, figsize=(14, 18), sharex=True)\n",
    "\n",
    "axs[0].plot(times, yaw_corrected, label='Yaw Corrected', color='tab:blue')\n",
    "axs[0].set_ylabel('Yaw (deg)', fontsize=14)\n",
    "axs[0].legend(loc='upper right')\n",
    "axs[0].grid(True)\n",
    "\n",
    "axs[1].plot(times, pitch, label='Pitch', color='tab:orange')\n",
    "axs[1].set_ylabel('Pitch (deg)', fontsize=14)\n",
    "axs[1].legend(loc='upper right')\n",
    "axs[1].grid(True)\n",
    "\n",
    "axs[2].plot(times, roll, label='Roll', color='tab:green')\n",
    "axs[2].set_ylabel('Roll (deg)', fontsize=14)\n",
    "axs[2].legend(loc='upper right')\n",
    "axs[2].grid(True)\n",
    "\n",
    "axs[3].plot(times, velocity, label='Velocity', color='tab:red') #this is prior to making the velocity constant, so it looks \"noisy\"\n",
    "axs[3].set_ylabel('Velocity (m/s)', fontsize=14)\n",
    "axs[3].legend(loc='upper right')\n",
    "axs[3].grid(True)\n",
    "\n",
    "axs[4].plot(times, elev, label='Elevation', color='tab:purple')\n",
    "axs[4].set_ylabel('Elevation (m)', fontsize=14)\n",
    "axs[4].set_xlabel('Time (s)', fontsize=14)\n",
    "axs[4].legend(loc='upper right')\n",
    "axs[4].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c83b333",
   "metadata": {},
   "source": [
    "# SAR Parameters: #\n",
    "Below are the SAR parameters used for the last 20250205 GM flightline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec854066",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 1.2288e9 #sampling frequency of the SNOWWI system\n",
    "t_p = 14e-6 #pulse width for Grand Mesa flightlines (determined preflight from slant range to ground)\n",
    "c = 3e8 #speed of light\n",
    "f0 = 5.39e9 #center frequency for C-band\n",
    "wavelength = c/f0\n",
    "print(\"Wavelength: \", wavelength, \"[m]\")\n",
    "print(\"PRF : \", prf, \"[Hz]\")\n",
    "V_r = constant_velocity #m/s\n",
    "del constant_velocity\n",
    "f_low = 340e6 #part of frequency stack for C-band\n",
    "f_high = 420e6 #part of frequency stack for C-band\n",
    "f_c = (f_high + f_low) / 2\n",
    "print(\"Center Frequency : \", f_c, \"[Hz]\")\n",
    "bandwidth = f_high - f_low\n",
    "print(\"Bandwidth : \", bandwidth, \"[Hz]\")\n",
    "chirp_delay = 0\n",
    "K_r = (f_high - f_low)/t_p\n",
    "print(\"Range Chirp Rate : \", K_r, \"[Hz/s]\")\n",
    "print(\"PRI : \", dt, \"[s]\")\n",
    "\n",
    "dx = np.mean(np.diff(uniform_distance))   #m/sample\n",
    "prf_eff = V_r / dx                        #samples/sec\n",
    "print(\"Effective PRF:\", prf_eff)\n",
    "#f_a = np.fft.fftfreq(N_az, d=1/prf_eff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d1df7f",
   "metadata": {},
   "source": [
    "# Quadrature Demodulation (via Hilbert): #\n",
    "Next, we need to convert the real-valued data to complex-valued which is performed using the Hilbert transform. Below is a great resource for more information on discrete complex downconversion.\n",
    "\n",
    "https://www.dsprelated.com/showarticle/153.php\n",
    "\n",
    "Since we are going to take FFTs and the FFT of a real-valued input is Hermitian-symmetric, we need to convert to complex values to get a single-sidebanded signal. A real-valued dataset would result in a double sidebanded FFT (folded over 0 Hz or DC) which would make it very difficult to distinguish direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c88b98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5, plot=False):\n",
    "    nyq   = 0.5 * fs\n",
    "    low   = lowcut  / nyq\n",
    "    high  = highcut / nyq\n",
    "    b, a  = butter(order, [low, high], btype='band')\n",
    "    #normalize at center frequency\n",
    "    center_freq = (lowcut + highcut) / 2\n",
    "    w, h = freqz(b, a, worN=[2*np.pi*center_freq/fs])\n",
    "    if plot:\n",
    "        w, h = freqz(b, a, worN=data.shape[1])\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(w * nyq / np.pi, abs(h), label='Frequency Response')  # Convert normalized frequency to Hz\n",
    "        plt.axvline(lowcut, color='red', linestyle='--', label='Low Cutoff Frequency')\n",
    "        plt.axvline(highcut, color='red', linestyle='--', label='High Cutoff Frequency')\n",
    "        plt.title('Frequency Response of Bandpass Filter')\n",
    "        plt.xlabel('Frequency (Hz)')\n",
    "        plt.ylabel('Gain')\n",
    "        plt.grid()\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    #b = b / abs(h[0])\n",
    "    y = filtfilt(b, a, data, axis=1) #forward/backward filtering to preserve phase\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35084e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_data = butter_bandpass_filter(radar_data, f_low-1e6, f_high+1e6, fs, order=5, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f98797",
   "metadata": {},
   "source": [
    "# (Optional) Troubleshooting Plot: #\n",
    "Plots the FFT of the middle azimuth line (so FFT over range)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245042ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fft_mid_azm = np.fft.fft(radar_data[radar_data.shape[0]//2, :])\n",
    "#fft_mid_azm_freqs = np.fft.fftfreq(len(fft_mid_azm), d=1/fs)\n",
    "#plt.figure(figsize=(10, 6), dpi=500)\n",
    "#plt.plot(fft_mid_azm_freqs, np.abs(fft_mid_azm), label='FFT of Middle Azimuth Bin', color='blue')\n",
    "#plt.axvline(x=340e6, color='red', linestyle='--', label='Low Frequency (340 MHz)')\n",
    "#plt.axvline(x=420e6, color='red', linestyle='--', label='High Frequency (420 MHz)')\n",
    "#plt.title('FFT of Middle Azimuth Bin', fontsize=24, fontweight='bold')\n",
    "#plt.xlabel('Frequency (Hz)', fontsize=20)\n",
    "#plt.ylabel('Magnitude', fontsize=20)\n",
    "#plt.xlim(0, fs/2) \n",
    "#plt.grid(True)\n",
    "#plt.legend(fontsize=16)\n",
    "#plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3a5cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytic_downconvert(data, fs, f_c):\n",
    "    \"\"\"Downconvert real-valued SAR data to complex baseband using Hilbert transform.\"\"\"\n",
    "    analytic = hilbert(data, axis=1)\n",
    "    N_rg = analytic.shape[1]\n",
    "    n = np.arange(N_rg)\n",
    "\n",
    "    mix = np.exp(-1j * 2 * np.pi * f_c * n / fs)\n",
    "    analytic *= mix\n",
    "\n",
    "    return analytic\n",
    "\n",
    "iq_data = analytic_downconvert(radar_data, fs, f_c)\n",
    "del radar_data  #free memory, doing this immediately after because radar_data is huge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d48b02",
   "metadata": {},
   "source": [
    "# Remove DC Bias: #\n",
    "I don't know if this is still needed but doing so just in case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e0fabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "iq_data -= iq_data.mean(axis=1, ).reshape(-1, 1) #remove DC bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8454bc",
   "metadata": {},
   "source": [
    "# Azimuth & Range Calculations: #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83977064",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iq_data[:,:50000] #preserving memory by removing half of the range samples\n",
    "N_az = data.shape[0]\n",
    "print(\"Number of Azimuth Lines : \", N_az)\n",
    "t = np.linspace(0, data.shape[0] / prf, data.shape[0])  #slow time\n",
    "\n",
    "N_rg = data.shape[1]\n",
    "print(\"Number of Range Samples : \", N_rg)\n",
    "dr = c / (2*fs)\n",
    "print(\"Range Separation : \", dr, \"[m]\")\n",
    "R_offset = 1.35e3 #range offset for Grand Mesa\n",
    "#H = 2247  #height of the platform above ground in meters\n",
    "Rmin = R_offset\n",
    "Rmax = Rmin + (N_rg * dr)\n",
    "print(\"Range Vector : \", Rmin, \"to\", Rmax, \"[m]\")\n",
    "R = np.linspace(Rmin, Rmax, N_rg)\n",
    "tau = 2 * R / c #fast time delay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7565e4",
   "metadata": {},
   "source": [
    "# First-Order MOCO: #\n",
    "First-order motion compensation corrects deviations of the platform trajectory from its ideal, straight-line path. Conceptually, if we imagine a straight reference line representing the nominal flight path, any deviation of the actual trajectory from this line introduces a change in the radar-to-target range. This range error translates directly into a phase error in the received signal.\n",
    "\n",
    "To correct for this, the actual trajectory is projected onto the reference (ideal) path, and a corresponding phase correction term is applied to the radar data to remove the range difference between the measured and reference trajectories. First-order MOCO compensates for phase errors due to translational motion deviations along the line of sight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c368a4d",
   "metadata": {},
   "source": [
    "# Calculating the LOS1 (first-order moco) Phase Term: #\n",
    "- LOS1 is line-of-sight phase term for 1st-order MOCO.\n",
    "This is performed by the following:\n",
    "$$\n",
    "rlos1 = -\\Delta y \\cdot \\cos{\\gamma_{l_{ref}}} + \\Delta z \\cdot \\sin{\\gamma_{l_{ref}}}\n",
    "$$\n",
    "\n",
    "where,\n",
    "\n",
    "$$\n",
    "\\gamma_{l_{ref}} = \\arcsin{\\frac{h}{r_{ref}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a759f97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_order_moco(delta_y, delta_z, wavelength, h, r_ref):\n",
    "    \"\"\"First-Order motion compensation which corrects for translational motion errors.\"\"\"\n",
    "    #y is LEFT, look is LEFT -> LOS_y = +cosψ, LOS_z = -sinψ\n",
    "    #use direction cosines without arcsin:\n",
    "    uz = np.clip(h / r_ref, -1.0, 1.0)                 # = sinψ  (>=0)\n",
    "    uy = np.sqrt(np.maximum(0.0, 1.0 - uz**2))         # = cosψ  (>=0)\n",
    "\n",
    "    #ΔR1 = -Δy*cosψ + Δz*sinψ   (left-looking, y=left)\n",
    "    dR1 = -delta_y * uy + delta_z * uz\n",
    "    H_mc1 = np.exp(-1j * (4*np.pi / wavelength) * dR1)\n",
    "    return H_mc1, dR1\n",
    "\n",
    "\n",
    "r_ref = R[R.shape[0] // 2]  #scalar ref slant range\n",
    "print(\"Reference Range:\", r_ref)\n",
    "H = 2247 #height per azimuth sample, this is a rough estimate, better estimates should be determined via DEM\n",
    "print(\"Height per Azimuth Sample:\", H)\n",
    "ratio = H / r_ref\n",
    "print(\"min:\", np.min(ratio), \"max:\", np.max(ratio))\n",
    "H_mc1, dR1 = first_order_moco(delta_y, delta_z, wavelength, H, r_ref)\n",
    "data = (data * H_mc1[:, None]).astype(np.complex64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a28c6d",
   "metadata": {},
   "source": [
    "# Calculate Doppler Bandwidth Using 3dB Sinc Beamwidth: #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab57f6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#low squint case:\n",
    "def doppler_bandwidth_estimation(V_r):\n",
    "    doppler_band = 2 * 0.886 * V_r\n",
    "    return doppler_band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22c5c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "dop_b_est = doppler_bandwidth_estimation(V_r)\n",
    "print(\"Estimated Doppler Bandwidth (Hz):\", dop_b_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d7d725",
   "metadata": {},
   "source": [
    "# Calulate Exposure Time: #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0f07f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exposure_time_estimation(dop_b_est, V_r):\n",
    "    \"\"\"Estimate the exposure time based on the Doppler bandwidth and velocity for low squint case.\"\"\"\n",
    "    exposure_time = 0.886 * V_r / dop_b_est\n",
    "    return exposure_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6f8e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exposure_time = exposure_time_estimation(dop_b_est, V_r)\n",
    "print(\"Estimated Exposure Time (s):\", exposure_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b8e3f6",
   "metadata": {},
   "source": [
    "# Convert Exposure Time to Azimuth Samples: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae5163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to convert exposure time to azimuth samples\n",
    "def exposure_time_to_azimuth_samples(exposure_time, prf):\n",
    "    \"\"\"Convert exposure time to azimuth samples.\"\"\"\n",
    "    azimuth_samples = int(np.round(exposure_time * prf))\n",
    "    return azimuth_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69774038",
   "metadata": {},
   "outputs": [],
   "source": [
    "azimuth_zero_pad_len = exposure_time_to_azimuth_samples(exposure_time, prf)\n",
    "print(\"Azimuth Zero Padding Length:\", azimuth_zero_pad_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8043f2",
   "metadata": {},
   "source": [
    "# Azimuth Fourier Transform: #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e928c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.pad(data, ((0, azimuth_zero_pad_len), (0, 0)), mode='constant') #pad to prevent circular convolution troubles\n",
    "data = np.fft.fft(data, axis=0).astype(np.complex64)\n",
    "f_a = np.fft.fftfreq(data.shape[0], d=1/prf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb295b65",
   "metadata": {},
   "source": [
    "# Calculate Doppler Bandwidth: #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98ea321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to determine Doppler centroid estimate from the data (brightest points in the range-Doppler image)\n",
    "def estimate_doppler_centroid(data, f_a):\n",
    "    \"\"\"\n",
    "    Estimate the Doppler centroid from the range-Doppler image.\n",
    "    Returns the estimated Doppler frequency and its index.\n",
    "    \"\"\"\n",
    "    mag = np.abs(data)\n",
    "    peak_doppler_indices = np.argmax(mag, axis=0)  #axis=0: Doppler dimension\n",
    "    peak_doppler_freqs = f_a[peak_doppler_indices]  #Doppler frequencies corresponding to the peak magnitude\n",
    "    return peak_doppler_freqs, peak_doppler_indices \n",
    "\n",
    "def calculate_squint_from_doppler(f_dc, wavelength, V_r):\n",
    "    \"\"\"\n",
    "    Calculate the squint angle from the Doppler centroid frequency.\n",
    "    f_dc: Doppler centroid frequency\n",
    "    wavelength: Wavelength of the radar signal\n",
    "    V_r: Mean velocity of the platform\n",
    "    \"\"\"\n",
    "    #squint angle formula\n",
    "    squint_angle = np.arcsin((f_dc * wavelength) / (2 * V_r))\n",
    "    return squint_angle #radians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d492587",
   "metadata": {},
   "outputs": [],
   "source": [
    "bw = np.deg2rad(3) #beamwidth in radians, estimated beamwidth for C-band is around 3 deg\n",
    "f_dc = estimate_doppler_centroid(data, f_a)[0]  #estimate Doppler centroid frequency\n",
    "f_dc_mean = np.mean(f_dc[17203:])  #mean Doppler centroid frequency\n",
    "print(\"Doppler Centroid Frequency (Hz):\", f_dc)\n",
    "print(\"Mean Doppler Centroid Frequency (Hz):\", f_dc_mean)\n",
    "squint_angle = calculate_squint_from_doppler(f_dc, wavelength, V_r)  #Calculate squint angle from Doppler centroid\n",
    "theta_sq = np.mean(squint_angle[17203:]) #was 17300:\n",
    "print(\"Mean Squint Angle (degrees):\", np.rad2deg(theta_sq))\n",
    "f_a_min = 2 * V_r / wavelength * np.sin(theta_sq + bw/2)\n",
    "f_a_max = 2 * V_r / wavelength * np.sin(theta_sq - bw/2)\n",
    "print(\"f_a_min: \", f_a_min, \"[Hz]\")\n",
    "print(\"f_a_max: \", f_a_max, \"[Hz]\")\n",
    "print(\"Doppler Bandwidth (Hz):\", np.abs(f_a_max - f_a_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6adafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot Doppler centroid bandwidth over Doppler spectrum\n",
    "plt.figure(figsize=(20, 10), dpi=500)\n",
    "plt.imshow(20 * np.log10(np.abs(np.fft.fftshift(data, axes=0))), vmin=60, vmax=100, aspect='auto', cmap='gray', interpolation='none', extent=[R[0], R[-1], f_a.max(), f_a.min()])\n",
    "\n",
    "# Overlay Doppler centroid and bandwidth\n",
    "if 'f_a_min' in locals() and 'f_a_max' in locals() and 'f_dc_mean' in locals():\n",
    "    plt.axhline(f_dc_mean, color='r', linestyle='--', linewidth=1.5, label=r'Doppler Centroid')\n",
    "    plt.axhline(f_a_min, color='g', linestyle='--', linewidth=1.5, label=r'$f_{a}$ Low')\n",
    "    plt.axhline(f_a_max, color='b', linestyle='--', linewidth=1.5, label=r'$f_{a}$ High')\n",
    "else:\n",
    "    print(\"Doppler centroid and bandwidth variables not found. Please run the Doppler centroid estimation cell.\")\n",
    "\n",
    "plt.title('Range/Doppler Domain (After Azimuth FFT)', fontsize=24, fontweight='bold')\n",
    "plt.xlabel('Slant Range [m]', fontsize=20)\n",
    "plt.ylabel(r'$f_a$ [Hz]', fontsize=20)\n",
    "\n",
    "cbar = plt.colorbar(label='Magnitude (dB)')\n",
    "cbar.ax.tick_params(labelsize=16)\n",
    "\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.legend(fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b7edb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del iq_data  #free memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbab53f",
   "metadata": {},
   "source": [
    "# Effective FM Rate: #\n",
    "- The effective FM chirp rate in range,\n",
    "$$\n",
    "K_s(f; r) = \\frac{K}{1+\\frac{(\\frac{2\\lambda K r}{c^2}(\\frac{\\lambda f}{2 V(r)})^2)}{{[1-\\left(\\frac{\\lambda f}{2 V(r)}\\right)^2]^{3/2}}}}\n",
    "$$\n",
    "\n",
    "- The range distortion factor,\n",
    "\n",
    "$$\n",
    "\\alpha(f; r) = \\frac{2\\lambda\\left(\\frac{\\lambda f}{2V(r)}\\right)^2}{c^2[1-\\left(\\frac{\\lambda f}{2V(r)}\\right)^2]^{3/2}}\n",
    "$$\n",
    "\n",
    "- Range distortion is not a function of the FM rate but is a function of the geometry\n",
    "- This factor, if not compensated leads to range defocus and has a strong dependence on Doppler frequency and a weak dependence on range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8257781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#corrected implementation for range distortion factor\n",
    "def range_distortion_factor(freq, wavelength, V_r):\n",
    "    numerator = 2 * wavelength * (wavelength * freq / (2 * V_r))**2\n",
    "    denominator = c**2 * (1 - (wavelength * freq / (2 * V_r))**2)**(3/2)\n",
    "    return numerator / denominator\n",
    "\n",
    "#corrected implementation for effective chirp rate\n",
    "def K_s(K_r, r_ref, freq, wavelength, V_r):\n",
    "    alpha = range_distortion_factor(freq, wavelength, V_r)\n",
    "    denominator = 1 + (K_r * r_ref * alpha)\n",
    "    return K_r / denominator\n",
    "\n",
    "\n",
    "#range_distortion_value = range_distortion_factor(f_a - f_dc_mean, wavelength, V_r).astype(np.float64)\n",
    "#print(\"Range distortion factor = \",range_distortion_value)\n",
    "#print(\"Maximum range distortion factor = \", max(abs(range_distortion_value)))\n",
    "#K_s_value = K_s(K_r, r_ref, f_a - f_dc_mean, wavelength, V_r).astype(np.float64)\n",
    "#print(\"Effective chirp rate (K_s) = \", K_s_value)\n",
    "#print(\"Maximum effective chirp rate = \", max(abs(K_s_value)), \"[Hz/s]\")\n",
    "#print(\"K_s Shape : \", K_s_value.shape)\n",
    "#print(\"range_distortion_value Shape : \", range_distortion_value.shape)\n",
    "\n",
    "fa_mask = (f_a >= f_a_max) & (f_a <= f_a_min) if f_a_max < f_a_min else (f_a >= f_a_min) & (f_a <= f_a_max)\n",
    "range_distortion_value = np.zeros_like(f_a)\n",
    "K_s_value = np.zeros_like(f_a)\n",
    "\n",
    "range_distortion_value[fa_mask] = range_distortion_factor(f_a[fa_mask] - f_dc_mean, wavelength, V_r)\n",
    "K_s_value[fa_mask] = K_s(K_r, r_ref, f_a[fa_mask] - f_dc_mean, wavelength, V_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a329be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(f_a[fa_mask], range_distortion_value[fa_mask], 'b.')\n",
    "plt.xlabel('$f$ [Hz]')\n",
    "plt.ylabel(r'$\\alpha(f)$')\n",
    "plt.title('Range Distortion Factor')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738109e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(f_a[fa_mask], K_s_value[fa_mask], 'b.')\n",
    "plt.xlabel('$f$ [Hz]')\n",
    "plt.ylabel(r'$K_e(f)$')\n",
    "plt.title('Effective Chirp Rate')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b433e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement curvature factor in a function\n",
    "def C_s(freq, wavelength, V_r):\n",
    "    numerator = 1\n",
    "    denominator = np.sqrt(1 - (wavelength * freq / (2 * V_r))**2)\n",
    "    return (numerator / denominator) - 1\n",
    "\n",
    "#C_s_dc_value = C_s(mean_doppler_centroid, wavelength, V_r).astype(np.float64)\n",
    "C_s_value = np.zeros_like(f_a)\n",
    "C_s_value[fa_mask] = C_s(f_a[fa_mask] - f_dc_mean, wavelength, V_r).astype(np.float64)\n",
    "print(\"Range Curvature Factor : \", C_s_value)\n",
    "print(\"Maximum range curvature factor : \", max(abs(C_s_value)))\n",
    "print(\"C_s Shape : \", C_s_value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580c4a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(f_a[fa_mask], C_s_value[fa_mask], 'b.')\n",
    "plt.xlabel('$f$ [Hz]')\n",
    "plt.ylabel(r'$C(f)$')\n",
    "plt.title('Range Curvature Factor')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4202aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tau_ref(r_ref, C_s, c=3e8):\n",
    "    return (2 * r_ref / c)*(1 + C_s)\n",
    "\n",
    "tau_ref_value = np.zeros_like(f_a)\n",
    "tau_ref_value[fa_mask] = tau_ref(r_ref, C_s_value[fa_mask], c).astype(np.float64)\n",
    "print(\"Time loci of the reference range : \", tau_ref_value, \"[s]\")\n",
    "print(\"Maximum time locus of the reference range : \", max(abs(tau_ref_value)), \"[s]\")\n",
    "print(\"Tau_ref Shape : \", tau_ref_value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cb1032",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(f_a[fa_mask], tau_ref_value[fa_mask], 'b.')\n",
    "plt.xlabel('Azimuth Frequency [Hz]')\n",
    "plt.ylabel(r'$\\tau_{ref}$ [s]')\n",
    "plt.title('Time Loci of the Reference Range')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e315587",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reference range curvature\n",
    "r_ref_curvature = 0.5 * c * tau_ref_value\n",
    "print(\"Reference range curvature: \", r_ref_curvature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587cf85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_1(K_s, C_s, tau, tau_ref):\n",
    "    return np.exp(-1j * np.pi * K_s * C_s * ((tau - tau_ref) ** 2))\n",
    "\n",
    "print(\"Range times = \", tau)\n",
    "print(\"Reference range times = \", tau_ref_value)\n",
    "phi_1_value = np.zeros(data.shape, dtype=np.complex64)  # initialize phi_1_value array\n",
    "print(\"Azimuth FFT shape = \", data.shape)\n",
    "\n",
    "#fa_mask = (f_a >= f_a_max) & (f_a <= f_a_min) if f_a_max < f_a_min else (f_a >= f_a_min) & (f_a <= f_a_max)\n",
    "#remember to use the same fa_mask in azimuth compression\n",
    "a_count = 0 \n",
    "for i in range(data.shape[0]):\n",
    "    if fa_mask[i]:\n",
    "        phi_1_value[i, :] = phi_1(K_s_value[i], C_s_value[i], tau, tau_ref_value[i])\n",
    "        a_count += 1\n",
    "    else:\n",
    "        phi_1_value[i, :] = 0.0\n",
    "\n",
    "print(\"First phase term = \", phi_1_value)\n",
    "print(\"First phase term shape = \", phi_1_value.shape)\n",
    "print(\"Number of valid azimuth lines = \", a_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66594da",
   "metadata": {},
   "source": [
    "# (Optional) Troubleshooting Plot: #\n",
    "Plots the first phase term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4139e776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(20,10), dpi=500)\n",
    "#plt.imshow(np.angle(np.fft.fftshift(phi_1_value, axes=0)), aspect='auto', cmap='hsv', interpolation='none', extent=[R[0], R[-1], f_a.max(), f_a.min()])\n",
    "#plt.axvline(x=R[R.shape[0]//2],color='r',linestyle='--',label='reference range')\n",
    "#plt.axhline(y=f_dc_mean, color='r', linestyle='--', label='Doppler centroid')\n",
    "#plt.plot(r_ref_curvature, f_a, 'b.', label='reference range curvature')\n",
    "\n",
    "#plt.title('First Phase Term', fontsize=24, fontweight='bold')\n",
    "#plt.xlabel('Range [m]', fontsize=20)\n",
    "#plt.ylabel('Azimuth Frequency [Hz]', fontsize=20)\n",
    "\n",
    "#cbar = plt.colorbar(label='Phase (radians)')\n",
    "#cbar.ax.tick_params(labelsize=16)\n",
    "\n",
    "#plt.xticks(fontsize=16)\n",
    "#plt.yticks(fontsize=16)\n",
    "#plt.legend()\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc611ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.multiply(data, phi_1_value).astype(np.complex64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35025901",
   "metadata": {},
   "outputs": [],
   "source": [
    "del range_distortion_value, phi_1_value, tau_ref_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327315f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_width = int(np.ceil((t_p * fs)/2))\n",
    "\n",
    "#always pad at the end of axis=1 (range dimension)\n",
    "data = np.pad(data, ((0, 0), (0, pad_width)), mode='constant')\n",
    "print(\"Data shape after padding:\", data.shape)\n",
    "\n",
    "data = np.fft.fft(data, axis=1).astype(np.complex64)\n",
    "\n",
    "f_r = np.fft.fftfreq(N_rg + pad_width, d=1/fs)\n",
    "\n",
    "print(\"Range FFT freq shape:\", f_r.shape)\n",
    "print(\"Range frequencies before shift:\", f_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1b5ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = np.fft.fft(data, axis=1).astype(np.complex64)\n",
    "#f_r = np.fft.fftfreq(N_rg, d=1/fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c64158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_2_1(f_tau, K_s, C_s):\n",
    "    phase_correction = np.exp(1j * np.pi * (f_tau**2) / (K_s * (1 + C_s))) #range focusing/compression\n",
    "    return phase_correction\n",
    "\n",
    "def phi_2_2(f_tau, r_ref, C_s, c=3e8):\n",
    "    linear_phase = np.exp(4j * (np.pi / c) * f_tau * (r_ref * C_s)) #RCMC\n",
    "    return linear_phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170e9e29",
   "metadata": {},
   "source": [
    "# Range Compression in Two-Dimensional Frequency Domain: #\n",
    "This achieves range compression via a two-dimensional frequency-domain matched filter (first term in the exponential below).\n",
    "\n",
    "$$\n",
    "\\Phi_2(f_\\tau, f; r_{ref}) = \\exp \\left( -j\\pi \\frac{f_\\tau^2}{K_s(f; f_{ref})[1 + C_s(f)]} \\right) \\cdot \\exp \\left( +j\\frac{4\\pi}{c} f_\\tau r_{ref} C_s(f) \\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95426ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_2_1_value = np.zeros(data.shape, dtype=np.complex64)\n",
    "fr_mask = np.abs(f_r) <= (K_r * t_p) / 2\n",
    "hamming_window = np.hamming(np.sum(fr_mask))\n",
    "window_idx = 0\n",
    "\n",
    "for j, fr in enumerate(f_r):\n",
    "    if not fr_mask[j]:\n",
    "        continue\n",
    "    taper = hamming_window[window_idx]\n",
    "    for i in range(data.shape[0]):\n",
    "        if fa_mask[i]:\n",
    "            denom = K_s_value[i] * (1 + C_s_value[i])\n",
    "            if denom != 0:\n",
    "                phi_2_1_value[i, j] = taper * np.exp(1j * np.pi * (fr**2) / denom)\n",
    "        else:\n",
    "            phi_2_1_value[i, j] = 0.0\n",
    "    window_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d7bcd7",
   "metadata": {},
   "source": [
    "# (Optional) Troubleshooting Plot:\n",
    "This plots the range compression phase term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95030dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(20,10), dpi=500)\n",
    "#plt.imshow(np.angle(np.fft.fftshift(phi_2_1_value)), aspect='auto', cmap='hsv', interpolation='none', extent=[f_r.min()/1e6, f_r.max()/1e6, f_a.max(), f_a.min()])\n",
    "\n",
    "#plt.title('Range Matched Filter', fontsize=24, fontweight='bold')\n",
    "#plt.xlabel(r'$f_{r}$ [MHz]', fontsize=20)\n",
    "#plt.ylabel(r'$f_{a}$ [Hz]', fontsize=20)\n",
    "\n",
    "#cbar = plt.colorbar(label='Phase (radians)')\n",
    "#cbar.ax.tick_params(labelsize=16)\n",
    "\n",
    "#plt.xticks(fontsize=16)\n",
    "#plt.yticks(fontsize=16)\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594523e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.multiply(data, phi_2_1_value).astype(np.complex64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15227978",
   "metadata": {},
   "outputs": [],
   "source": [
    "del phi_2_1_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d85cfbe",
   "metadata": {},
   "source": [
    "# (Optional) Troubleshooting Plot:\n",
    "This plots the data in the range/Doppler domain as a quality check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9747b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(20,10), dpi=500)\n",
    "#plt.imshow(20*np.log10(np.abs(np.fft.ifft(np.fft.fftshift(data), axis=1))), vmin=80, vmax=120, aspect='auto', cmap='gray', interpolation='none', extent=[R[0], R[-1], f_a.max(), f_a.min()])\n",
    "#plt.axvline(x=R[R.shape[0]//2],color='r',linestyle='--',label='reference range')\n",
    "#plt.plot(r_ref_curvature, f_a, 'b.', label='reference range curvature')\n",
    "\n",
    "#plt.title('Range Compressed (Magnitude)', fontsize=24, fontweight='bold')\n",
    "#plt.xlabel(r'Slant Range [m]', fontsize=20)\n",
    "#plt.ylabel(r'$f_{a}$ [Hz]', fontsize=20)\n",
    "\n",
    "#cbar = plt.colorbar(label='Magnitude (dB)')\n",
    "#cbar.ax.tick_params(labelsize=16)\n",
    "\n",
    "#plt.xticks(fontsize=16)\n",
    "#plt.yticks(fontsize=16)\n",
    "#plt.legend()\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eda1044",
   "metadata": {},
   "source": [
    "# Range Cell Migration Correction in Two-Dimensional Frequency Domain: #\n",
    "This achieves range cell migration correction in the two-dimensional frequency domain (second term in the exponential below).\n",
    "\n",
    "$$\n",
    "\\Phi_2(f_\\tau, f; r_{ref}) = \\exp \\left( -j\\pi \\frac{f_\\tau^2}{K_s(f; f_{ref})[1 + C_s(f)]} \\right) \\cdot \\exp \\left( +j\\frac{4\\pi}{c} f_\\tau r_{ref} C_s(f) \\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f16da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_2_2_value = np.zeros_like(data, dtype=np.complex64)\n",
    "\n",
    "#apply boolean mask to include azimuth frequencies within bandwidth\n",
    "#fa_mask = (f_a >= f_a_max) & (f_a <= f_a_min) if f_a_max < f_a_min else (f_a >= f_a_min) & (f_a <= f_a_max)\n",
    "for i in range(data.shape[0]):\n",
    "    if fa_mask[i]:\n",
    "        phi_2_2_value[i, :] = phi_2_2(f_r, r_ref, C_s_value[i], c)\n",
    "    else:\n",
    "        phi_2_2_value[i, :] = 0.0  # Set to zero outside the valid bandwidth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a844d624",
   "metadata": {},
   "source": [
    "# (Optional) Troubleshooting Plot:\n",
    "This plots the the RCMC phase term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6163e6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(20,10), dpi=500)\n",
    "#plt.imshow(np.angle(np.fft.fftshift(phi_2_2_value)), aspect='auto', cmap='hsv', interpolation='none', extent=[f_r.min(), f_r.max(), f_a.max(), f_a.min()])\n",
    "#plt.axvline(x=R[R.shape[0]//2],color='r',linestyle='--', linewidth=1, label='reference range')\n",
    "#plt.plot(r_ref_curvature, f_a, 'b--', linewidth=0.5, label='reference range curvature')\n",
    "\n",
    "#plt.title('RCMC Phase Term (Phase)', fontsize=24, fontweight='bold')\n",
    "#plt.xlabel(r'$f_{\\tau}$ [MHz]', fontsize=20)\n",
    "#plt.ylabel(r'$f$ [Hz]', fontsize=20)\n",
    "\n",
    "#cbar = plt.colorbar(label='Phase (radians)')\n",
    "#cbar.ax.tick_params(labelsize=16)\n",
    "\n",
    "#plt.xticks(fontsize=16)\n",
    "#plt.yticks(fontsize=16)\n",
    "#plt.legend()\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a3ab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.multiply(data, phi_2_2_value).astype(np.complex64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471d2f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "del phi_2_2_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407f543b",
   "metadata": {},
   "source": [
    "# (Optional) Troubleshooting Plot:\n",
    "This plots the the data in the range/Doppler domain as a quality check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f950e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(20,10), dpi=500)\n",
    "#plt.imshow(20*np.log10(np.abs(np.fft.ifft(np.fft.fftshift(data), axis=1))), vmin=80, vmax=120, aspect='auto', cmap='gray', interpolation='none', extent=[R[0], R[-1], f_a.max(), f_a.min()])\n",
    "#plt.axvline(x=R[R.shape[0]//2],color='r',linestyle='--',label='reference range')\n",
    "#plt.plot(r_ref_curvature, f_a, 'b.', label='reference range curvature')\n",
    "\n",
    "#plt.title('RCMC', fontsize=24, fontweight='bold')\n",
    "#plt.xlabel(r'Slant Range [m]', fontsize=20)\n",
    "#plt.ylabel(r'$f_{a}$ [Hz]', fontsize=20)\n",
    "\n",
    "#cbar = plt.colorbar(label='Magnitude (dB)')\n",
    "#cbar.ax.tick_params(labelsize=16)\n",
    "\n",
    "#plt.xticks(fontsize=16)\n",
    "#plt.yticks(fontsize=16)\n",
    "#plt.legend()\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54fad91",
   "metadata": {},
   "source": [
    "# Range Inverse Fourier Transform: #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c2055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.fft.ifft(data, axis=1).astype(np.complex64)\n",
    "\n",
    "data = data[:, :N_rg] #remove extra range padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dcba6f",
   "metadata": {},
   "source": [
    "# Second-Order MOCO: #\n",
    "Second-order motion compensation corrects for residual motion errors that remain after first-order correction, particularly those caused by range-dependent motion effects. While first-order MOCO assumes all targets experience the same range correction (using a single reference range), second-order MOCO compensates for each range cell experiencing a slightly different motion-induced path length error.\n",
    "\n",
    "These higher-order terms arise from the curvature of the flight path and the variation of the line-of-sight geometry across the swath. In practice, second-order MOCO applies a range-dependent phase correction to each pixel or range bin, accounting for differing range deviations between the actual and reference trajectories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305e6c7a",
   "metadata": {},
   "source": [
    "# Calculating LOS2 (second-order moco) Phase Term: #\n",
    "- LOS2 is line-of-sight phase term for 2nd-order MOCO. This is performed by the following:\n",
    "$$\n",
    "rlos2 = -\\Delta y \\cdot \\cos{\\gamma_{l_{r}}} + \\Delta z \\cdot \\sin{\\gamma_{l_{r}}}\n",
    "$$\n",
    "\n",
    "where,\n",
    "\n",
    "$$\n",
    "\\gamma_{l_{r}} = \\arcsin{\\frac{h}{r}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67caef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_order_moco(delta_y, delta_z, rlos1, lam, h, R):\n",
    "    uz = np.clip(h / R, -1.0, 1.0)                     #sinψ(r)\n",
    "    uy = np.sqrt(np.maximum(0.0, 1.0 - uz**2))         #cosψ(r)\n",
    "\n",
    "    #left-looking, y=left:\n",
    "    rlos = -delta_y[:, None] * uy[None, :] + delta_z[:, None] * uz[None, :]\n",
    "    rlos2 = rlos - rlos1[:, None]\n",
    "    return np.exp(-1j * (4*np.pi / lam) * rlos2).astype(np.complex64), rlos2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0388ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#azimuth ifft because 2nd-order moco needs to be applied to 2-D time domain data\n",
    "data = np.fft.ifft(data, axis=0).astype(np.complex64)\n",
    "data = data[:N_az, :]  #remove extra azimuth padding\n",
    "print(\"Data shape after azimuth IFFT: \", data.shape)\n",
    "\n",
    "#2nd-order moco\n",
    "H_mc2, rlos2 = second_order_moco(delta_y, delta_z, dR1, wavelength, H, R)\n",
    "#apply 2nd-order moco\n",
    "data = (data * H_mc2).astype(np.complex64)\n",
    "\n",
    "#azimuth fft back to range/Doppler domain for azimuth compression\n",
    "data = np.pad(data, ((0, azimuth_zero_pad_len), (0, 0)), mode='constant')\n",
    "data = np.fft.fft(data, axis=0).astype(np.complex64)\n",
    "print(\"Data shape after azimuth FFT: \", data.shape)\n",
    "#f_a already calculated above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60606aff",
   "metadata": {},
   "source": [
    "# Third Phase Term: #\n",
    "- The phase residual term (range/Doppler phase multiplier) is given by:\n",
    "$$\n",
    "\\Phi_3(\\tau, f) = \\exp \\left( -j \\frac{2\\pi}{\\lambda} c\\tau \\left[ 1 - \\left[ 1 - \\left( \\frac{\\lambda f}{2V(r = \\tau c/2)} \\right)^2 \\right]^{1/2} \\right] + j\\Theta_D(f; r) \\right)\n",
    "$$\n",
    "\n",
    "- Theta delta term:\n",
    "$$\n",
    "\\Theta_D(f; r) = \\frac{4\\pi}{c^2} K_s(f; f_{ref}) \\left[ 1 + C_s(f) \\right] C_s(f) (r - r_{ref})^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d693a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def theta_D(K_s, C_s, r, r_ref, c=3e8):\n",
    "    return (4 * np.pi / (c**2)) * K_s * (1 + C_s) * C_s * ((r - r_ref)**2)\n",
    "\n",
    "def phi_3(tau, freq, wavelength, V_r, theta_D_val):\n",
    "    return np.exp(\n",
    "        -1j * (2 * np.pi / wavelength) * c * tau *\n",
    "        (1 - np.sqrt(1 - (((wavelength * freq) / (2 * V_r))**2)))\n",
    "        + (1j * theta_D_val)\n",
    "    )\n",
    "\n",
    "print(\"Range time = \", tau, \"[s]\")\n",
    "phi_3_value = np.zeros((data.shape[0], data.shape[1]), dtype=np.complex64)\n",
    "theta_D_value = np.zeros((data.shape[0], data.shape[1]), dtype=np.float64)\n",
    "print(\"Azimuth frequencies = \", f_a)\n",
    "\n",
    "#create boolean mask for valid Doppler frequencies\n",
    "fa_mask = (f_a >= f_a_max) & (f_a <= f_a_min) if f_a_max < f_a_min else (f_a >= f_a_min) & (f_a <= f_a_max)\n",
    "\n",
    "#construct full-length taper with zeros outside valid region\n",
    "azimuth_window = np.zeros_like(f_a)\n",
    "azimuth_window[fa_mask] = np.hamming(np.sum(fa_mask))\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    taper = azimuth_window[i]\n",
    "    if taper > 0:\n",
    "        theta_D_value[i, :] = theta_D(K_s_value[i], C_s_value[i], R, r_ref)\n",
    "        phi_3_value[i, :] = taper * phi_3(tau, f_a[i] - f_dc_mean, wavelength, V_r, theta_D_value[i, :])\n",
    "    else:\n",
    "        theta_D_value[i, :] = 0.0\n",
    "        phi_3_value[i, :] = 0.0\n",
    "\n",
    "print(\"theta_D = \", theta_D_value)\n",
    "print(\"phi_3 = \", phi_3_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edf59d3",
   "metadata": {},
   "source": [
    "# (Optional) Troubleshooting Plot:\n",
    "The plots below represent the residual compensation term as a result of the chirp scaling operation (first phase term) and the phase of the azimuth compression term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11ed940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(20,10), dpi=500)\n",
    "#plt.imshow(np.fft.fftshift(theta_D_value, axes=0), aspect='auto', cmap='hsv', interpolation='none', extent=[R[0], R[-1], f_a.max(), f_a.min()])\n",
    "\n",
    "#plt.title('Residual Phase Term (Phase)', fontsize=24, fontweight='bold')\n",
    "#plt.xlabel(r'Slant Range [m]', fontsize=20)\n",
    "#plt.ylabel(r'$f$ [Hz]', fontsize=20)\n",
    "\n",
    "#cbar = plt.colorbar(label='Phase (radians)')\n",
    "#cbar.ax.tick_params(labelsize=16)\n",
    "\n",
    "#plt.xticks(fontsize=16)\n",
    "#plt.yticks(fontsize=16)\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93efe494",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(20,10), dpi=500)\n",
    "#plt.imshow(np.angle(np.fft.fftshift(phi_3_value, axes=0)), aspect='auto', cmap='hsv', interpolation='none', extent=[R[0], R[-1], f_a.max(), f_a.min()])\n",
    "\n",
    "#plt.title('Azimuth Compression Phase Term (Phase)', fontsize=24, fontweight='bold')\n",
    "#plt.xlabel(r'Slant Range [m]', fontsize=20)\n",
    "#plt.ylabel(r'$f$ [Hz]', fontsize=20)\n",
    "\n",
    "#cbar = plt.colorbar(label='Phase (radians)')\n",
    "#cbar.ax.tick_params(labelsize=16)\n",
    "\n",
    "#plt.xticks(fontsize=16)\n",
    "#plt.yticks(fontsize=16)\n",
    "\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfc1652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiply range ifft by phi_3\n",
    "data = np.multiply(data, phi_3_value).astype(np.complex64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788f05c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del phi_3_value, theta_D_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72ddd31",
   "metadata": {},
   "source": [
    "# Azimuth Inverse Fourier Transform: #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e71b386",
   "metadata": {},
   "outputs": [],
   "source": [
    "azm_ifft_output = np.fft.ifft(data, axis=0).astype(np.complex64)\n",
    "azm_ifft_output = azm_ifft_output[:N_az, :]  #remove extra azimuth padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b26b51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26344e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = datetime.now()\n",
    "print(f\"Processing completed in {end_time - start_time} seconds.\")\n",
    "print(\"Script finished successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1164012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "along_track_distance =  times * V_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed39160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 5), dpi=500)\n",
    "ax = plt.gca()  #get the current axis\n",
    "im = ax.imshow(20*np.log10(np.abs(azm_ifft_output)), vmin=20, vmax=70, aspect='equal', cmap='gray', interpolation='none', extent=[R[0], R[-1], along_track_distance[-1], 0])\n",
    "\n",
    "#add title and labels\n",
    "plt.title(f'CSA Image ({f0 / 1e9} GHz, Files {start_idx} to {stop_idx} from Flightline: 20250205T235149)', fontsize=12, fontweight='bold')\n",
    "plt.xlabel('Slant Range [m]', fontsize=16)\n",
    "plt.ylabel('Along-Track Distance [m]', fontsize=16)\n",
    "\n",
    "#create an axis on the right side of the current axis for the color bar\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"1%\", pad=0.05)\n",
    "\n",
    "#create the color bar and make it the same height as the image\n",
    "cbar = plt.colorbar(im, cax=cax)\n",
    "cbar.ax.tick_params(labelsize=16)\n",
    "cbar.set_label('Magnitude (dB)', fontsize=16)\n",
    "\n",
    "#set the font size for ticks\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.savefig(f'csa_image_20250205T235149_files_{start_idx}_to_{stop_idx}_1st2ndMOCO.png', dpi=1000)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7185908",
   "metadata": {},
   "source": [
    "# Corner Reflector Analysis: #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51906530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import maximum_filter\n",
    "\n",
    "#magnitude and a small “window” to look for maxima\n",
    "mag = np.abs(azm_ifft_output)\n",
    "footprint = np.ones((15,15))    # 15×15-pixel neighborhood\n",
    "\n",
    "#find pixels that equal the local max in their 15×15 window\n",
    "local_max = (mag == maximum_filter(mag, footprint=footprint))\n",
    "\n",
    "#threshold these peaks to ignore speckle\n",
    "thr = np.percentile(mag, 99.99975)  #top 0.1% amplitudes\n",
    "candidates = np.where(local_max & (mag >= thr))\n",
    "cr_rows, cr_cols = candidates\n",
    "\n",
    "print(\"Found\", len(cr_rows), \"reflector candidates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276130c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.imshow(20*np.log10(mag), cmap='gray', vmin=20, vmax=70)\n",
    "plt.scatter(cr_cols, cr_rows, s=30, facecolors='none', edgecolors='yellow')\n",
    "plt.title(\"Local‐maxima corner‐reflector picks\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fcddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#slant-range in meters:\n",
    "r_axis = np.arange(azm_ifft_output.shape[1]) * (c/(2*fs))\n",
    "#along-track in meters (centered on each CR later):\n",
    "t_axis = np.arange(azm_ifft_output.shape[0]) / prf\n",
    "v_avg  = np.mean(velocity)  # or your known platform speed\n",
    "\n",
    "#plot cuts for each CR\n",
    "img_db = 20*np.log10(mag)\n",
    "\n",
    "for idx, (r, c) in enumerate(zip(cr_rows, cr_cols)):\n",
    "    range_profile = img_db[r, :] #range cut through CR\n",
    "    az_profile    = img_db[:, c] #azimuth cut through CR\n",
    "    az_axis = (t_axis - t_axis[r]) * v_avg #zero-center the along-track axis at the CR\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,4), dpi=300)\n",
    "\n",
    "    #range cuts\n",
    "    ax1.plot(r_axis, range_profile, '-k')\n",
    "    ax1.axvline(r_axis[c], color='r', linestyle='--')\n",
    "    ax1.set_xlabel(\"Slant‐Range (m)\")\n",
    "    ax1.set_ylabel(\"Amplitude (dB)\")\n",
    "    ax1.set_title(f\"CR#{idx+1} Range Cut\")\n",
    "\n",
    "    #azimuth cuts\n",
    "    ax2.plot(az_axis, az_profile, '-k')\n",
    "    ax2.axvline(0, color='r', linestyle='--')\n",
    "    ax2.set_xlabel(\"Along‐Track Offset (m)\")\n",
    "    ax2.set_ylabel(\"Amplitude (dB)\")\n",
    "    ax2.set_title(f\"CR#{idx+1} Azimuth Cut\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17528aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_3db_beamwidth(x_axis, profile_db):\n",
    "    \"\"\"Given an axis x_axis (meters) and a profile in dB,\n",
    "    returns (half_power_level, left_idx, right_idx, beamwidth_m)\"\"\"\n",
    "    peak_idx   = np.argmax(profile_db)\n",
    "    peak_level = profile_db[peak_idx]\n",
    "    half_power = peak_level - 3.0\n",
    "\n",
    "    #find left crossing\n",
    "    left_candidates = np.where(profile_db[:peak_idx] <= half_power)[0]\n",
    "    left_idx = left_candidates[-1] if left_candidates.size else 0\n",
    "\n",
    "    #find right crossing\n",
    "    right_candidates = np.where(profile_db[peak_idx:] <= half_power)[0]\n",
    "    right_idx = peak_idx + right_candidates[0] if right_candidates.size else len(profile_db)-1\n",
    "\n",
    "    bw = x_axis[right_idx] - x_axis[left_idx]\n",
    "    return half_power, left_idx, right_idx, bw\n",
    "\n",
    "for idx, (r, c) in enumerate(zip(cr_rows, cr_cols)):\n",
    "    az_profile = img_db[:, c]\n",
    "    az_axis    = (t_axis - t_axis[r]) * v_avg\n",
    "\n",
    "    #compute 3 dB points\n",
    "    hp_lvl, iL, iR, bw = compute_3db_beamwidth(az_axis, az_profile)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6,4), dpi=300)\n",
    "\n",
    "    ax.plot(az_axis, az_profile, '-k')\n",
    "    ax.axhline(hp_lvl, color='C1', linestyle='--',\n",
    "               label=f'–3 dB @ {hp_lvl:.1f} dB')\n",
    "    ax.axvline( az_axis[iL], color='C1', linestyle=':')\n",
    "    ax.axvline( az_axis[iR], color='C1', linestyle=':')\n",
    "    ax.text(0, hp_lvl-1, f'BW₃dB = {bw:.1f} m',\n",
    "            color='C1', ha='center', va='top',\n",
    "            bbox=dict(facecolor='white', alpha=0.6, edgecolor='none'))\n",
    "\n",
    "    ax.set_xlabel(\"Along‐Track Offset (m)\")\n",
    "    ax.set_ylabel(\"Amplitude (dB)\")\n",
    "    ax.set_title(f\"CR#{idx+1} Azimuth Cut & 3 dB Beamwidth\")\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csa_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
